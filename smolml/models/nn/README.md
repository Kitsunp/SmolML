# SmolML - Redes Neuronales: Retropropagaci√≥n hasta el l√≠mite

Bienvenido a la secci√≥n de redes neuronales de SmolML! Habiendo establecido nuestros objetos Value para diferenciaci√≥n autom√°tica y MLArray para manejar datos (ver secci√≥n 'core'), ahora podemos construir modelos que aprenden. Esta gu√≠a te llevar√° a trav√©s de los conceptos fundamentales, desde una sola neurona hasta una red neuronal completamente entrenable, y c√≥mo se representan en SmolML.

> **IMPORTANTE**: Como nuestra implementaci√≥n est√° hecha completamente en Python, manejar la diferenciaci√≥n autom√°tica de una red neuronal completa es muy costoso computacionalmente. Si planeas ejecutar un ejemplo, recomendamos empezar con una red muy peque√±a y luego escalar. Crear una red neuronal demasiado grande para tu computadora podr√≠a hacer que se congele üôÇ 

<div align="center">
  <img src="https://github.com/user-attachments/assets/e5315fca-5dd6-4c9c-9cf3-bf46edfbb40c" width="600">
</div>

## La Neurona: Un Peque√±o Tomador de Decisiones

En el coraz√≥n de una red neuronal est√° la neurona (o nodo). Piensa en ella como una peque√±a unidad computacional que recibe varias entradas, las procesa, y produce una sola salida.

<div align="center">
  <img src="https://github.com/user-attachments/assets/2f95fdfe-1676-4a0b-9e10-95ecdf9155b6" width="600">
</div>

Esto es lo que una neurona hace conceptualmente:

- **Suma Ponderada (Weighted Sum)**: Cada conexi√≥n de entrada a la neurona tiene un peso asociado. La neurona multiplica cada valor de entrada por su peso correspondiente. Estos pesos son cruciales ‚Äì son lo que la red aprende ajustando durante el entrenamiento, determinando la influencia de cada entrada.
- **Sesgo (Bias)**: La neurona luego agrega un t√©rmino de sesgo a esta suma ponderada. El sesgo permite a la neurona desplazar su salida hacia arriba o abajo, independiente de sus entradas. Esto ayuda a la red a ajustar datos que no necesariamente pasan por el origen.
- **Funci√≥n de Activaci√≥n (Activation Function)**: Finalmente, el resultado de la suma ponderada + sesgo se pasa a trav√©s de una funci√≥n de activaci√≥n. Esta funci√≥n introduce no linealidad, lo cual es vital. Sin no linealidad, una pila de m√∫ltiples capas se comportar√≠a como una sola capa, limitando la habilidad de la red para aprender patrones complejos. Las funciones de activaci√≥n comunes incluyen ReLU, Tanh, y Sigmoid.

Mientras SmolML no tiene una clase Neurona independiente para esta secci√≥n (ya que frecuentemente es m√°s eficiente trabajar con capas directamente), la l√≥gica de muchas de esas neuronas operando en paralelo est√° encapsulada dentro de nuestra DenseLayer. Cada caracter√≠stica de salida de una DenseLayer puede pensarse como la salida de una neurona conceptual.

## Capas: Organizando Neuronas

Una sola neurona no es muy poderosa por s√≠ sola. Las redes neuronales organizan neuronas en capas. El tipo m√°s com√∫n es una Capa Densa (Dense Layer) (tambi√©n conocida como Capa Completamente Conectada).

¬øQu√© hace una capa densa?

En una capa densa, cada neurona en la capa recibe entrada de cada neurona en la capa anterior (o de los datos de entrada cruda si es la primera capa).

Conceptualmente, una capa densa realiza dos pasos principales, construyendo sobre la l√≥gica de la neurona:

1. **Transformaci√≥n Lineal (Linear Transformation)**: Toma un vector de entrada (o un lote de vectores de entrada) y realiza una multiplicaci√≥n de matrices con una matriz de pesos (`W`) y agrega un vector de sesgo (`b`).
   - Cada fila en el vector de entrada se conecta a cada columna en la matriz de pesos. Si tienes caracter√≠sticas input_size y quieres caracter√≠sticas output_size de esta capa (es decir, neuronas output_size conceptuales), la matriz de pesos `W` tendr√° una forma de (input_size, output_size). Cada elemento $W_ij$ es el peso conectando la i-√©sima caracter√≠stica de entrada a la j-√©sima neurona en la capa.
   - El vector de sesgo b tendr√° elementos output_size, uno para cada neurona.
   - Matem√°ticamente: $z=entrada√óW+b$.
   - En SmolML, cuando creas una DenseLayer (de `layer.py`), especificas input_size y output_size. La capa luego inicializa self.weights (nuestro `W`) y self.biases (nuestro `b`) como objetos `MLArray`. Estos son los par√°metros entrenables de la capa.

```python
# De layer.py
class DenseLayer:
    def __init__(self, input_size: int, output_size: int, ...):
        self.weights = weight_initializer.initialize(input_size, output_size) # MLArray
        self.biases = zeros(1, output_size) # MLArray
        ...
```

2. **Funci√≥n de Activaci√≥n (Activation Function)**: El resultado (`z`) de esta transformaci√≥n lineal se pasa luego elemento por elemento a trav√©s de una funci√≥n de activaci√≥n no lineal elegida (ej., ReLU, Tanh).
   - Esto se aplica a la salida de cada neurona conceptual en la capa.
   - En SmolML, especificas la activation_function al crear una DenseLayer, y se aplica en el m√©todo forward:

```python
# De layer.py
class DenseLayer:
    ...
    def forward(self, input_data):
        z = input_data @ self.weights + self.biases # Transformaci√≥n lineal
        return self.activation_function(z)      # Activaci√≥n
```

El m√©todo forward esencialmente define c√≥mo fluyen los datos a trav√©s de la capa. Porque `input_data`, `self.weights`, y `self.biases` son `MLArray`s (que usan objetos `Value` internamente), todas las operaciones autom√°ticamente construyen el grafo computacional necesario para retropropagaci√≥n.

## Redes Neuronales: Apilando Capas

El verdadero poder de las redes neuronales viene de apilar m√∫ltiples capas. La salida de una capa se convierte en la entrada de la siguiente. Esto permite a la red aprender caracter√≠sticas jer√°rquicas ‚Äì capas anteriores podr√≠an aprender patrones simples (como bordes en una imagen), mientras capas posteriores los combinan para aprender conceptos m√°s complejos (como formas u objetos).

<div align="center">
  <img src="https://github.com/user-attachments/assets/3979a284-0b29-4110-b6c5-dfe1a13f50b9" width="600">
</div>

### La Clase NeuralNetwork (neural_network.py)

En SmolML, la clase `NeuralNetwork` maneja esta secuencia de capas y orquesta todo el proceso de entrenamiento.

- **Inicializaci√≥n (__init__)**:
  - Creas una NeuralNetwork proporcion√°ndole una lista de objetos de capa (ej., una secuencia de instancias DenseLayer), una loss_function (para medir qu√© tan "incorrectas" est√°n las predicciones de la red), y un optimizer (que define c√≥mo actualizar los par√°metros de la capa).

```python
# De neural_network.py
class NeuralNetwork:
    def __init__(self, layers: list, loss_function: callable, optimizer: optimizers.Optimizer = optimizers.SGD()):
        self.layers = layers
        self.loss_function = loss_function
        self.optimizer = optimizer
```

- **Paso Hacia Adelante (Forward Pass) (forward)**:
  - El paso hacia adelante de la red es directo: toma los datos de entrada y los pasa secuencialmente a trav√©s de cada capa en su lista. La salida de la capa i se convierte en la entrada de la capa i+1.

```python
# De neural_network.py
class NeuralNetwork:
    ...
    def forward(self, input_data):
        for layer in self.layers: # Pasar datos a trav√©s de cada capa
            input_data = layer.forward(input_data)
        return input_data # Salida final de la red
```

Este paso hacia adelante encadenado, porque cada m√©todo forward de capa usa operaciones MLArray, construye un gran grafo computacional desde la entrada inicial hasta la predicci√≥n final de la red.

## Ense√±ando a la Red: El Loop de Entrenamiento

"Aprender" en una red neuronal significa ajustar los pesos y sesgos en todas sus capas para hacer mejores predicciones. Esto se logra a trav√©s de un proceso llamado entrenamiento, que t√≠picamente involucra los siguientes pasos repetidos por muchas √©pocas (pases a trav√©s de todo el dataset):

1. **Paso Hacia Adelante (Forward Pass)**:
   - Alimentar los datos de entrada (`X`) a trav√©s de la red usando `network.forward(X)` para obtener predicciones (`y_pred`). Como hemos visto, esto tambi√©n construye el grafo computacional.

2. **Calcular P√©rdida (Compute Loss)**:
   - Comparar las predicciones de la red (`y_pred`) con los valores objetivo reales (`y`) usando la loss_function especificada (ej., Error Cuadr√°tico Medio para regresi√≥n, Entrop√≠a Cruzada para clasificaci√≥n).
   - La p√©rdida es un solo Value (frecuentemente envuelto en un `MLArray`) que cuantifica qu√© tan mal se desempe√±√≥ la red en este lote de datos. Este `Value` de p√©rdida es el nodo final de nuestro grafo computacional actual.

3. **Paso Hacia Atr√°s (Backward Pass) (Retropropagaci√≥n)**:
   - ¬°Aqu√≠ es donde brilla la magia de nuestros objetos `Value` (de la secci√≥n 'core')! Llamamos `loss.backward()`.
   - Este comando dispara el proceso de diferenciaci√≥n autom√°tica. Camina hacia atr√°s a trav√©s del grafo computacional completo (desde la p√©rdida hasta cada peso y sesgo en cada `DenseLayer`, e incluso la entrada `X`) y calcula el gradiente de la p√©rdida con respecto a cada uno de estos objetos `Value`. El atributo `.grad` de cada `Value` (y por tanto cada elemento en nuestros par√°metros `MLArray`) se llena.
   - Esto nos dice cu√°nto cambiar√≠a un peque√±o cambio en cada `weight` o `bias` la p√©rdida general.

4. **Actualizar Par√°metros (Update Parameters)**:
   - Ahora que sabemos la "direcci√≥n de mayor ascenso" para la p√©rdida (los gradientes), el optimizador interviene. Usa estos gradientes (y su propia l√≥gica interna, como una tasa de aprendizaje) para ajustar los pesos y sesgos en cada capa. El objetivo es empujarlos en la direcci√≥n opuesta a sus gradientes para reducir la p√©rdida.
   - En SmolML, el m√©todo `NeuralNetwork.train` itera a trav√©s de sus capas y llama `layer.update(self.optimizer, ...)` para cada una. Este m√©todo, a su vez, usa el optimizador para modificar layer.weights y layer.biases.

5. **Reiniciar Gradientes (Reset Gradients)**:
   - Los gradientes calculados por `loss.backward()` son acumulados (agregados) al atributo `.grad` de cada `Value`. Antes de la siguiente iteraci√≥n de entrenamiento (el siguiente paso forward/backward), es absolutamente crucial reiniciar estos gradientes de vuelta a cero.
   - Esto se hace usando el m√©todo `.restart()` en los `MLArray`s relevantes (todos los pesos y sesgos en cada capa, y a veces X e y si son parte de grafos persistentes). Si no hici√©ramos esto, los gradientes de iteraciones previas influenciar√≠an incorrectamente las actualizaciones en la iteraci√≥n actual.
   - Ver√°s esto en `NeuralNetwork.train()`:

```python
# Dentro de NeuralNetwork.train() despu√©s de actualizaciones de par√°metros
X.restart()
y.restart()
for layer in self.layers:
    layer.weights.restart()
    layer.biases.restart()
```

Al repetir c√≠clicamente estos pasos, la NeuralNetwork gradualmente ajusta sus par√°metros DenseLayer, aprovechando el poder de diferenciaci√≥n autom√°tica de Value y MLArray para minimizar la p√©rdida y "aprender" de los datos.